---
permalink: /home
title: "Home"
excerpt: ""

---
<span id='home'></span>

# ğŸ˜Š About Me  

I am a Ph.D. candidate at **The Hong Kong Polytechnic University**, co-supervised by [**Prof. Haibo Hu**](https://haibohu.org/) and [**Dr. Minxin Du**](https://duminxin.github.io/).  
My research focuses on the **security, privacy, and reliability of large language models (LLMs)**.  
Before starting my Ph.D., I received my **B.Eng. in Electronics and Communication Engineering** from **Sun Yat-sen University (SYSU)** in 2024.  

---

## ğŸ”¬ Research Interests  

- **Machine Unlearning for Large Language Models (LLMs):**  
  Designing efficient and robust algorithms that enable LLMs to selectively *forget* specific data or behaviors while preserving their overall capability.  
  My research explores two key scenarios:  
  - ğŸ§© **Single Unlearning:** Removing a specific set of data or knowledge from a pre-trained model in a one-time unlearning request, ensuring minimal performance degradation.  
  - ğŸ” **Continual Unlearning:** Extending unlearning to long sequences of deletion requests, addressing cumulative forgetting, stability, and reversibility issues over time.  

- **LLM Security and Trustworthiness:**  
  Investigating the robustness of LLMs against unlearning attacks like relearning and quantization perturbations to ensure safety and integrity in real-world applications.  

---

  
<!--<span class="anchor" id="news"></span>-->
# ğŸ”¥ News

- ğŸ—“ï¸ **August 2025** â€” Our paper is accepted to EMNLP 2025 (Main Conference)!
- ğŸ—“ï¸ **June 2025** â€” Invited to review for [ACM Transactions on the Web (TWEB)](https://dl.acm.org/journal/tweb).
- ğŸ—“ï¸ **June 2025** â€” Invited by [EMNLP](https://2025.emnlp.org/) to serve as a secondary (external) reviewer.
- ğŸ—“ï¸ **May 2025** â€” My personal homepage officially launched!

<!--<span class="anchor" id="publications"></span>-->
# ğŸ“ Publications 
- **Does Math Reasoning Improve General LLM Capabilities? Understanding Transferability of LLM Reasoning**  
  arXiv preprint: [2507.00432](https://arxiv.org/abs/2507.00432) â€¢ [PDF](https://arxiv.org/pdf/2507.00432)  
 Maggie Huan, Yuetai Li, Tuney Zheng, **Xiaoyu Xu**, Seungone Kim, Minxin Du, Radha Poovendran, Graham Neubig, Xiang Yue

- **Unlearning Isn't Deletion: Investigating Reversibility of Machine Unlearning in LLMs**  
  arXiv preprint: [2505.16831](https://arxiv.org/abs/2505.16831) â€¢ [PDF](https://arxiv.org/pdf/2505.16831.pdf)  
  **Xiaoyu Xu**, Xiang Yue, Yang Liu, Qingqing Ye, Haibo Hu, Minxin Du
  
- **OBLIVIATE: Robust and Practical Machine Unlearning for Large Language Models**  
  EMNLP 2025 (Main Conference): [2505.04416](https://arxiv.org/abs/2505.04416) â€¢ [PDF](https://arxiv.org/pdf/2505.04416.pdf)  
  **Xiaoyu Xu**, Minxin Du, Qingqing Ye, Haibo Hu
  
# ğŸ“– Educations
- *2020.09 â€“ 2024.06*, Bachelor of Engineering in Electronics and Communication Engineering, Sun Yat-sen University (SYSU)  
- *2024.09 â€“ present*, Ph.D. Candidate, The Hong Kong Polytechnic University 


# ğŸ¯ Interests
- Fitness enthusiast: Passionate about strength training, cardio, and maintaining a healthy lifestyle.  
- Music lover: Enjoy listening to Mandopop artists such as Jay Chou, G.E.M., JJ Lin, and David Tao.  

 <a href="https://clustrmaps.com/site/1c73j"  title="ClustrMaps"><img src="//www.clustrmaps.com/map_v2.png?d=EsVhO2oJdnAEt2aXO6s9mWYkyN16gPxWAWyR7ALlNyc&cl=ffffff" /></a>
